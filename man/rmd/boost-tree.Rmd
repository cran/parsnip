# Engine Details

```{r, child = "setup.Rmd", include = FALSE}
```

Engines may have pre-set default arguments when executing the model fit call. For this type of model, the template of the fit calls are below:

## xgboost

```{r xgboost-reg}
boost_tree() %>% 
  set_engine("xgboost") %>% 
  set_mode("regression") %>% 
  translate()
```

```{r xgboost-csl}
boost_tree() %>% 
  set_engine("xgboost") %>% 
  set_mode("classification") %>% 
  translate()
```

Note that, for most engines to `boost_tree()`, the `sample_size` argument is in terms of the _number_ of training set points. The `xgboost` package parameterizes this as the  _proportion_ of training set samples instead. When using the `tune`, this **occurs automatically**. 

If you would like to use a custom range when tuning `sample_size`, the `dials::sample_prop()` function can be used in that case. For example, using a  parameter set: 

```{r xgb-update, eval = FALSE}
mod <- 
  boost_tree(sample_size = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

# update the parameters using the `dials` function
mod_param <- 
  mod %>% 
  parameters() %>% 
  update(sample_size = sample_prop(c(0.4, 0.9)))
```

Finally, note that `xgboost` models require that non-numeric predictors (e.g., factors) must be converted to dummy variables or some other numeric representation. By default, when using `fit()` with `xgboost`, a one-hot encoding is used to convert factor predictors to indicator variables. 


## C5.0

```{r C5.0-csl}
boost_tree() %>% 
  set_engine("C5.0") %>% 
  set_mode("classification") %>% 
  translate()
```

Note that [C50::C5.0()] does not require factor predictors to be converted  to indicator variables. `fit()` does not affect the encoding of the predictor values (i.e. factors stay factors) for this model.

## spark

```{r spark-reg}
boost_tree() %>% 
  set_engine("spark") %>% 
  set_mode("regression") %>% 
  translate()
```

```{r spark-csl}
boost_tree() %>% 
  set_engine("spark") %>% 
  set_mode("classification") %>% 
  translate()
```

`fit()` does not affect the encoding of the predictor values (i.e. factors stay factors) for this model.

## Parameter translations

The standardized parameter names in parsnip can be mapped to their original names in each engine that has main parameters. Each engine typically has a different default value (shown in parentheses) for each parameter.

```{r echo = FALSE, results = "asis"}
get_defaults_boost_tree <- function() {
  tibble::tribble(
    ~model,         ~engine,          ~parsnip,                 ~original,  ~default,
    "boost_tree", "xgboost",      "tree_depth",                "max_depth", get_arg("parsnip", "xgb_train", "max_depth"),
    "boost_tree", "xgboost",           "trees",                 "nrounds",  get_arg("parsnip", "xgb_train", "nrounds"),
    "boost_tree", "xgboost",      "learn_rate",                     "eta",  get_arg("parsnip", "xgb_train", "eta"),
    "boost_tree", "xgboost",            "mtry",        "colsample_bytree",  get_arg("parsnip", "xgb_train", "colsample_bytree"),
    "boost_tree", "xgboost",           "min_n",        "min_child_weight",  get_arg("parsnip", "xgb_train", "min_child_weight"),
    "boost_tree", "xgboost",  "loss_reduction",                   "gamma",  get_arg("parsnip", "xgb_train", "gamma"),
    "boost_tree", "xgboost",     "sample_size",               "subsample",  get_arg("parsnip", "xgb_train", "subsample"),
    "boost_tree",    "C5.0",           "trees",                "trials",    get_arg("parsnip", "C5.0_train", "trials"),
    "boost_tree",    "C5.0",           "min_n",                "minCases",  get_arg("C50", "C5.0Control", "minCases"),
    "boost_tree",    "C5.0",     "sample_size",                  "sample",  get_arg("C50", "C5.0Control", "sample"),
    "boost_tree", "spark",        "tree_depth",               "max_depth",  get_arg("sparklyr", "ml_gradient_boosted_trees", "max_depth"),
    "boost_tree", "spark",             "trees",                "max_iter",  get_arg("sparklyr", "ml_gradient_boosted_trees", "max_iter"),
    "boost_tree", "spark",        "learn_rate",               "step_size",  get_arg("sparklyr", "ml_gradient_boosted_trees", "step_size"),
    "boost_tree", "spark",              "mtry", "feature_subset_strategy",  "see below",
    "boost_tree", "spark",             "min_n",  "min_instances_per_node",  get_arg("sparklyr", "ml_gradient_boosted_trees", "min_instances_per_node"),
    "boost_tree", "spark",    "loss_reduction",        "min_info_gain",     get_arg("sparklyr", "ml_gradient_boosted_trees", "min_info_gain"),
    "boost_tree", "spark",       "sample_size",        "subsampling_rate",  get_arg("sparklyr", "ml_gradient_boosted_trees", "subsampling_rate"),

  )
}
convert_args("boost_tree")
```

For spark, the default `mtry` is the square root of the number of predictors for classification, and one-third of the predictors for regression.
